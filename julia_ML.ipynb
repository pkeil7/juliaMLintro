{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first time run this:\n",
    "#using Pkg; Pkg.add([\"Flux\",\"ClimateTools\",\"BSON\",\"GeoMakie\", \"CairoMakie\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flux Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My first MLP:\n",
    "\n",
    "Flux imports some structures (classes) and methods in your namesapce by default, such as `Dense()` and `σ`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Chain(\n",
    "  Dense(2, 3, σ), # 2 input features, 3 output features, sigmoid activation\n",
    "  Dense(3, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: you should normally be able to access the docstring via `?Dense`. But there is a vscode bug that returns an error related to Latex...\n",
    "Here is a workaround:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Markdown\n",
    "Base.showable(::MIME\"text/markdown\", ::Markdown.MD) = false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to get information about all methods with the same name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods(Dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to our model: Access weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typeof(model[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model[1].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model[1].bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = rand(Float32,2) # input features\n",
    "model(x) # output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods(Flux.mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods(Flux.crossentropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Climate Data Example: Train a CNN on ERA5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to train a CNN to classify the month of year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using ClimateTools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check out dataset that comes with the repo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset(\"era5_sst_global_5.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data into memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssts = load(\"era5_sst_global_5.nc\", \"sst\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using GeoMakie, CairoMakie\n",
    "fig = Figure(size = (500, 300), Contour = (; labelsize = 14, labelfont = :bold))\n",
    "ax1 = GeoAxis(fig[1,1]; title = \"ERA5 SSTs at $(ssts.data.axes[3][1])\")\n",
    "contourf!(ax1, ssts.data.axes[1][:], ssts.data.axes[2][:], ssts.data.data[:,:,1])\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size(ssts.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_dim = size(ssts.data.axes[3])[1]\n",
    "println(\"The dataset has $time_dim months of data\")\n",
    "\n",
    "# Define the number of years and months\n",
    "num_years = Int(time_dim ./ 12) #broadcasting division\n",
    "num_months = 12\n",
    "\n",
    "# Subset the final 10 years of data for testing\n",
    "test_years = 10\n",
    "train_years = num_years .- test_years;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = replace(ssts.data.data[:,:,1:(train_years * num_months)], NaN => 280.0)\n",
    "test_data = replace(ssts.data.data[:,:,(train_years * num_months + 1):end], NaN => 280.0) ; # use ; to suppress output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = 1:12\n",
    "ys_train = repeat(ys, train_years)\n",
    "ys_test = repeat(ys, test_years);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data, divide by std not possible due to zeros\n",
    "\n",
    "X_train_norm = (train_data .- mean(train_data, dims=3)) #./ std(train_data, dims=3)\n",
    "X_test_norm = (test_data .- mean(test_data, dims=3)) #./ std(test_data, dims = 3);\n",
    "\n",
    "#add channel dimension\n",
    "# flux expects data to be [width, height, channels, samples]\n",
    "\n",
    "X_train = reshape(X_train_norm, (size(X_train_norm, 1),  size(X_train_norm, 2), 1, size(X_train_norm, 3)))\n",
    "X_test = reshape(X_test_norm, (size(X_test_norm, 1),  size(X_test_norm, 2), 1, size(X_test_norm, 3)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys_train = Flux.onehotbatch(ys_train, 1:12)\n",
    "ys_test = Flux.onehotbatch(ys_test, 1:12);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "model = Chain(\n",
    "    Conv((5, 5), 1=>4, relu),\n",
    "    MaxPool((2, 2)),\n",
    "    Conv((3, 3), 4=>8, relu),\n",
    "    MaxPool((2, 2)),\n",
    "    Conv((3, 3), 8=>16, relu),\n",
    "    MaxPool((2, 2)),\n",
    "    Flux.flatten,\n",
    "    Dense(224, 64, relu),\n",
    "    Dense(64, num_months),\n",
    "    softmax\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = Flux.DataLoader((X_train, ys_train), batchsize=32, shuffle=true)\n",
    "test_loader = Flux.DataLoader((X_test, ys_test), batchsize=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check accuracy before training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function accuracy(loader)\n",
    "    acc = 0.0\n",
    "    for (X_batch, y_batch) in loader\n",
    "        acc += mean(Flux.onecold(model(X_batch)) .== Flux.onecold(y_batch))\n",
    "    end\n",
    "    return acc / length(loader)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"Training accuracy: \", accuracy(train_loader))\n",
    "println(\"Testing accuracy: \", accuracy(test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "loss(model, x, y) = Flux.crossentropy(model(x), y) # model is first argument\n",
    "opt = Flux.setup(Adam(), model)\n",
    "\n",
    "# Train the model\n",
    "epochs = 10\n",
    "\n",
    "for epoch in 1:epochs\n",
    "    Flux.train!(loss, model, train_loader, opt)\n",
    "    println(\"Epoch $epoch complete\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"Training accuracy: \", accuracy(train_loader))\n",
    "println(\"Testing accuracy: \", accuracy(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "using BSON: @save\n",
    "@save \"mymodel.bson\" model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the data above to create a toy GP problem. E.g. you could predict SST at a certain gridpoint from neighbouring gridpoints.  Research https://github.com/JuliaGaussianProcesses for more."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.3",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
